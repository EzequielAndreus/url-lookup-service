---
description: "Task list for Malware URL Detection API implementation"
---

# Tasks: Malware URL Detection API

**Feature**: 001-malware-url-detection  
**Branch**: `001-malware-url-detection`  
**Input**: Design documents from `/specs/001-malware-url-detection/`  
**Prerequisites**: plan.md âœ…, spec.md âœ…, research.md âœ…, data-model.md âœ…, contracts/ âœ…  

**Organization**: Tasks grouped by user story (US1, US2, US3) to enable independent implementation and testing.

## Format: `- [ ] [ID] [P?] [Story] Description with file path`

- **[P]**: Task can run in parallel (different files, no blocking dependencies)
- **[Story]**: User story this task belongs to (US1, US2, US3)
- **File paths**: Include exact paths for clarity and traceability

---

## Phase 1: Setup (Shared Infrastructure)

**Purpose**: Project initialization, dependencies, and shared configuration

- [x] T001 Create project structure per implementation plan (pyproject.toml, src/, tests/, data/)
- [x] T002 [P] Initialize Python 3.11+ project with pip/poetry and add dependencies in pyproject.toml (FastAPI, uvicorn, pydantic, httpx, aiofiles, pytest, pytest-asyncio, cachetools)
- [x] T003 [P] Create configuration management system in src/config.py (database paths, cache settings, timeout values)
- [x] T004 [P] Create pytest configuration in tests/conftest.py (async fixtures, mocking helpers, test database setup)
- [x] T005 [P] Create shared test fixtures in tests/fixtures/ (sample_malware_urls.csv, sample_malware_urls.json, mock_http_server.py)
- [x] T006 [P] Set up logging infrastructure in src/utils/logging.py (structured logging, request ID correlation, audit trail format)
- [x] T007 Create FastAPI application initialization in src/main.py (app creation, middleware setup, route mounting placeholder)
- [x] T008 [P] Check/Update .gitignore for Python project (venv/, __pycache__/, .env, *.pyc, htmlcov/)

**Checkpoint**: All project structure ready, dependencies installable, conftest.py enables async tests

---

## Phase 2: Foundational (Blocking Prerequisites)

**Purpose**: Core infrastructure blocking prerequisites for ALL user stories

**âš ï¸ CRITICAL**: No user story work can begin until this phase is complete

- [x] T009 [P] Create abstract database loader interface in src/services/database_loaders/base.py (BaseLoader class, async lookup() method, ThreatInfo return type)
- [x] T010 [P] Implement Pydantic models in src/models/url_check.py (URLCheckRequest, URLCheckResponse with validation)
- [x] T011 [P] Implement Pydantic models in src/models/malware_db.py (ThreatInfo, URLCache, MalwareDatabase configuration models)
- [x] T012 Create file-based malware database loader in src/services/database_loaders/file_loader.py (load CSV/JSON, async lookup, memory-efficient)
- [x] T013 Create HTTP endpoint malware database loader in src/services/database_loaders/http_loader.py (async httpx queries, timeout handling, error resilience)
- [x] T014 [P] Create caching utility in src/utils/cache.py (TTL-based in-memory cache, configurable size, cache hit/miss tracking)
- [x] T015 Create malware checker orchestrator in src/services/malware_checker.py (multi-database query coordination, parallel execution with asyncio.gather(), aggregation logic)
- [x] T016 Set up FastAPI router placeholder in src/api/urlinfo.py (empty GET route, ready for implementation)

**Checkpoint**: Loaders, models, and orchestrator ready; can be tested in isolation

---

## Phase 3: User Story 1 - Check URL for Malware (Priority: P1) ðŸŽ¯ MVP

**Goal**: Core API functionality - client submits URL, receives malicious/safe response via simple JSON. Fully async, handles concurrent requests.

**Independent Test**: Can be fully tested by calling GET /urlinfo/1/{hostname}/{path} with known URLs and verifying response format and accuracy.

### Tests for User Story 1 (Contract + Integration)

> **WRITE THESE TESTS FIRST - ENSURE THEY FAIL BEFORE IMPLEMENTATION**

- [x] T017 [P] [US1] Contract test for URL info endpoint request/response format in tests/contract/test_urlinfo_contract.py (valid URL returns 200, response has url/is_malicious/timestamp/cached fields, all required fields present)
- [x] T018 [P] [US1] Contract test for successful URL lookup (malware found) in tests/contract/test_urlinfo_contract.py (POST known malicious URL, verify is_malicious=true)
- [x] T019 [P] [US1] Contract test for successful URL lookup (safe URL) in tests/contract/test_urlinfo_contract.py (POST known safe URL, verify is_malicious=false)
- [x] T020 [P] [US1] Contract test for response headers in tests/contract/test_urlinfo_contract.py (X-Request-ID present, X-Cached header present, Content-Type is application/json)
- [x] T021 [P] [US1] Integration test for end-to-end malware detection workflow in tests/integration/test_malware_detection.py (URL submitted â†’ validated â†’ databases queried â†’ response returned, all in async context)
- [x] T022 [P] [US1] Integration test for concurrent request handling in tests/integration/test_malware_detection.py (100 concurrent requests submitted, all complete without blocking, all responses received)
- [x] T023 [US1] Integration test for cache hit behavior in tests/integration/test_malware_detection.py (same URL queried twice, second response marked cached=true, latency improves)

### Implementation for User Story 1

- [x] T024 [US1] Implement URLValidator.validate() method in src/services/url_validator.py (accepts URL string, validates format, returns normalized URL or raises ValueError with detail)
- [x] T025 [P] [US1] Implement MalwareChecker.__init__() in src/services/malware_checker.py (initialize all loaders from config, set timeouts, prepare for queries)
- [x] T026 [P] [US1] Implement MalwareChecker.check_url() in src/services/malware_checker.py (query all loaders in parallel, aggregate results, return boolean is_malicious)
- [x] T027 [US1] Implement GET /urlinfo/1/{hostname_and_port}/{original_path_and_query_string} route in src/api/urlinfo.py (parse path parameters, reconstruct full URL, validate, check, return response)
- [x] T028 [US1] Mount urlinfo router in FastAPI app in src/main.py (add router to app, enable CORS if needed)
- [x] T029 [US1] Implement request ID generation and response headers in src/api/urlinfo.py (X-Request-ID header generation/echo, X-Cached header, logging with request context)
- [x] T030 [US1] Add audit logging for each URL lookup in src/services/malware_checker.py (log URL, databases queried, result, timestamp, loader response times)
- [x] T031 [US1] Implement caching in MalwareChecker.check_url() in src/services/malware_checker.py (check cache before querying databases, store result in cache with TTL)

**Checkpoint**: User Story 1 fully functional and testable independently. Core API working, handles single and concurrent requests, returns correct responses, logs all activity. âœ…

---

## Phase 4: User Story 2 - Validate URL Input (Priority: P1)

**Goal**: Input validation with clear error messages. Rejects invalid URLs before database queries. Handles all edge cases.

**Independent Test**: Can be fully tested by submitting various URL formats (valid, invalid, edge cases) and verifying rejection with appropriate error messages.

### Tests for User Story 2 (Contract + Integration + Unit)

> **WRITE THESE TESTS FIRST - ENSURE THEY FAIL BEFORE IMPLEMENTATION**

- [x] T032 [P] [US2] Contract test for empty URL rejection in tests/contract/test_urlinfo_contract.py (POST /urlinfo/1//, returns 400 with detail message)
- [x] T033 [P] [US2] Contract test for missing scheme rejection in tests/contract/test_urlinfo_contract.py (POST /urlinfo/1/example.com/path, returns 400 with scheme error detail)
- [x] T034 [P] [US2] Contract test for missing domain rejection in tests/contract/test_urlinfo_contract.py (POST /urlinfo/1/?query=value, returns 400 with domain error detail)
- [x] T035 [P] [US2] Contract test for URL exceeding max length rejection in tests/contract/test_urlinfo_contract.py (POST extremely long URL, returns 400)
- [x] T036 [P] [US2] Contract test for error response format in tests/contract/test_urlinfo_contract.py (400 errors include detail, type, request_id fields in JSON)
- [x] T037 [P] [US2] Unit test for URL validator with empty input in tests/unit/test_url_validator.py (empty string raises ValueError with specific message)
- [x] T038 [P] [US2] Unit test for URL validator with missing scheme in tests/unit/test_url_validator.py (no http/https raises ValueError)
- [x] T039 [P] [US2] Unit test for URL validator with missing domain in tests/unit/test_url_validator.py (no hostname raises ValueError)
- [x] T040 [P] [US2] Unit test for URL validator with oversized URL in tests/unit/test_url_validator.py (>2048 chars raises ValueError)
- [x] T041 [P] [US2] Unit test for URL validator with valid URLs in tests/unit/test_url_validator.py (accepts http://, https://, with/without port, with/without path)
- [x] T042 [P] [US2] Unit test for URL normalization (query params preserved) in tests/unit/test_url_normalization.py (example.com?a=1&b=2 â†’ normalized preserves query)
- [x] T043 [P] [US2] Unit test for URL normalization (fragments preserved) in tests/unit/test_url_normalization.py (example.com#section â†’ normalized preserves fragment)
- [x] T044 [P] [US2] Unit test for URL normalization (scheme defaults) in tests/unit/test_url_normalization.py (http://example.com â†’ https://example.com normalization)
- [x] T045 [P] [US2] Unit test for URL normalization (domain lowercased) in tests/unit/test_url_normalization.py (Example.COM â†’ example.com)
- [x] T046 [P] [US2] Integration test for validation before database query in tests/integration/test_malware_detection.py (invalid URL rejected, database loaders never called, no log entry for database query)

### Implementation for User Story 2

- [x] T047 [US2] Implement URLValidator.validate_and_normalize() method in src/services/url_validator.py (full validation logic, error messages for each failure type, normalization)
- [x] T048 [P] [US2] Add validation error handling in src/api/urlinfo.py (catch ValueError from validator, return 400 with detail message, include request_id)
- [x] T049 [US2] Add request ID to all error responses in src/api/urlinfo.py (400/500 errors include request_id for audit tracing)
- [x] T050 [US2] Add input validation logging in src/services/url_validator.py (log validation failures with reason, request context)
- [x] T051 [P] [US2] Test URL with query parameters edge case in tests/unit/test_url_validator.py (verify query string preserved and validated correctly)
- [x] T052 [P] [US2] Test URL with internationalized domain names in tests/unit/test_url_validator.py (verify IDN handling, non-ASCII characters accepted)
- [x] T053 [P] [US2] Test URL with port number in tests/unit/test_url_validator.py (example.com:8080 accepted and normalized correctly)
- [x] T054 [P] [US2] Test null/missing URL parameter in tests/contract/test_urlinfo_contract.py (missing hostname_and_port returns 400)

**Checkpoint**: All input validation working. Invalid URLs rejected with clear error messages. All edge cases handled. Error logging transparent. User Story 2 fully functional.

---

## Phase 5: User Story 3 - Handle Lookup Performance (Priority: P2)

**Goal**: Sub-500ms response times under normal load. 100+ concurrent requests without blocking. Caching improves repeated lookups.

**Independent Test**: Can be fully tested by submitting multiple concurrent requests and measuring response times, verifying that performance meets baseline expectations.

### Tests for User Story 3 (Integration + Performance)

> **WRITE THESE TESTS FIRST - ENSURE THEY FAIL BEFORE IMPLEMENTATION**

- [x] T055 [P] [US3] Performance test for single URL lookup latency in tests/integration/test_malware_detection.py (measure time for single URL, verify <500ms p95 over 100 requests)
- [x] T056 [P] [US3] Performance test for concurrent request handling in tests/integration/test_malware_detection.py (submit 100 concurrent requests, measure response time distribution, verify all complete within reasonable time)
- [x] T057 [P] [US3] Performance test for cache hit improvement in tests/integration/test_malware_detection.py (first request ~X ms, cached request <10ms, demonstrate cache effectiveness)
- [x] T058 [P] [US3] Performance test for database timeout handling in tests/integration/test_malware_detection.py (simulate slow database, verify timeout occurs, response continues with other loaders)
- [x] T059 [P] [US3] Load test with Apache Bench or similar in tests/integration/test_malware_detection.py (ab -n 1000 -c 100, verify throughput and no failures)
- [x] T060 [P] [US3] Integration test for parallel database queries in tests/integration/test_database_loaders.py (multiple loaders queried simultaneously, not sequentially, response time optimized)

### Implementation for User Story 3

- [x] T061 [US3] Implement database query timeout in src/services/malware_checker.py (asyncio.wait_for() with 5 second timeout per loader, catch TimeoutError gracefully)
- [x] T062 [US3] Implement parallel database queries with asyncio.gather() in src/services/malware_checker.py (all loaders queried concurrently, not sequentially)
- [x] T063 [P] [US3] Implement cache TTL mechanism in src/utils/cache.py (entries expire after configured TTL, expired entries not returned)
- [x] T064 [P] [US3] Implement cache size limits in src/utils/cache.py (max entries configurable, LRU eviction when full)
- [x] T065 [P] [US3] Add performance logging in src/services/malware_checker.py (log loader response times, cache hit/miss, total request time)
- [x] T066 [P] [US3] Configure connection pooling in src/services/database_loaders/http_loader.py (httpx.AsyncClient with limits, reuse across requests)
- [x] T067 [US3] Implement partial failure handling in src/services/malware_checker.py (if some loaders timeout/fail, continue with others, only 503 if ALL fail)
- [x] T068 [US3] Add performance monitoring response header in src/api/urlinfo.py (X-Response-Time header with millisecond timing)
- [x] T069 [P] [US3] Test response time degradation under high load in tests/integration/test_malware_detection.py (verify <1000ms even with 100+ concurrent, no timeouts)

**Checkpoint**: Performance baseline met. Concurrent requests handled without blocking. Caching improves response times. User Story 3 complete.

---

## Phase 6: Polish & Cross-Cutting Concerns

**Purpose**: Testing infrastructure, documentation, error handling refinement, deployment readiness

- [x] T070 [P] Add docstrings to all public methods in src/services/, src/models/, src/api/ (document parameters, return types, exceptions)
- [x] T071 [P] Create comprehensive error handler middleware in src/main.py (catch all exceptions, return 500 with request_id, log stack trace)
- [x] T072 [P] Implement health check endpoint in src/main.py (GET /health returns 200 if databases accessible, 503 if all fail)
- [x] T073 [P] Create README.md with setup, running, testing, API usage instructions (build on quickstart.md)
- [x] T074 [P] Create pyproject.toml with all dependencies, entry point, build config (python 3.11+, FastAPI, pytest, etc.)
- [x] T075 [P] Add type hints to all functions in src/ (enable mypy type checking, catch type errors early)
- [x] T076 [P] Add linting configuration (ruff.toml or similar) for code style enforcement
- [x] T077 Create integration test for graceful database failure in tests/integration/test_malware_detection.py (simulate all loaders unavailable, returns 503 with clear error message)
- [x] T078 [P] Add metrics collection in src/utils/logging.py (track request count, response times, errors for observability)
- [x] T079 [P] Create example .env file with configuration templates (.env.example)
- [x] T080 Implement request timeout handling at API layer in src/api/urlinfo.py (if malware_checker.check_url() takes >10 seconds, return 503)
- [x] T081 [P] Add CORS configuration in src/main.py (allow cross-origin requests if needed for frontend)
- [x] T082 [P] Test concurrent requests at 1000+ level in tests/integration/test_malware_detection.py (demonstrate scalability beyond MVP baseline)
- [x] T083 [P] Create performance tuning guide in documentation (cache TTL, pool size, timeout values, how to adjust)
- [x] T084 Final integration test suite run (all tests pass, >80% code coverage, no warnings)

**Checkpoint**: All tests passing, code documented, error handling comprehensive, ready for deployment

---

## Implementation Order & Dependencies

```
Phase 1: Setup
    â†“
Phase 2: Foundational (blocking)
    â”œâ”€â†’ Phase 3: User Story 1 (can start after Phase 2 complete)
    â”œâ”€â†’ Phase 4: User Story 2 (can start after Phase 2 complete)
    â””â”€â†’ Phase 5: User Story 3 (can start after Phase 2 complete)
         (US3 depends on caching from Phase 2)
    â†“
Phase 6: Polish & Cross-cutting
```

**Parallel Execution Opportunities**:

Within Phase 1:
- T002, T003, T004, T005, T006, T008 can run in parallel
- Only T001 must complete first

Within Phase 2:
- T009, T010, T011, T014 can run in parallel
- T012, T013 depend on T009 only
- T015 depends on T012, T013, T011
- T016 has no dependencies

Within Phase 3 (User Story 1):
- All T017-T023 tests can be written in parallel
- T024, T025 can run in parallel
- T026 depends on T024, T025
- T027 depends on T026
- T028-T031 can run in parallel after T027

Within Phase 4 (User Story 2):
- All T032-T046 tests can be written in parallel
- T047, T048 can run in parallel after T024 complete
- T049-T054 can run in parallel with T047, T048

Within Phase 5 (User Story 3):
- All T055-T060 tests can be written in parallel
- T061-T069 can run in parallel

**Suggested MVP Scope** (Minimum Viable Product - can deploy and demonstrate):
- Phase 1: Setup âœ…
- Phase 2: Foundational âœ…
- Phase 3: User Story 1 âœ…
- Phase 4: User Story 2 (validation) âœ…
- Phase 5: Core performance (T061-T062 only)
- Phase 6: Minimum (health check, README, error handler)

This MVP delivers:
- âœ… URL check endpoint working
- âœ… Input validation with errors
- âœ… Multi-database support
- âœ… Async/concurrent request handling
- âœ… Simple JSON response
- âœ… Audit logging
- âœ… Deployable and runnable

Performance optimization (User Story 3 full), caching, advanced scaling in follow-up iteration.

---

## Task Validation Checklist

âœ… **All tasks follow format**: `- [ ] [ID] [P?] [Story] Description with file path`  
âœ… **Task IDs sequential**: T001-T084 in execution order  
âœ… **User stories mapped**: US1 (T017-T031), US2 (T032-T054), US3 (T055-T069)  
âœ… **Test-first organization**: Tests listed before implementation for each user story  
âœ… **Parallelizable tasks marked [P]**: Independent file operations  
âœ… **File paths explicit**: All tasks reference exact source/test file locations  
âœ… **Incremental delivery**: Each user story independently testable and deployable  
âœ… **No implementation details in spec**: Tasks describe user-facing behavior  
âœ… **Constitution principles applied**: Edge cases (US2, US3), logging (all), async (US1, US3), incremental (all)  

---

## Next Steps

1. âœ… Review all 84 tasks for clarity and completeness
2. âœ… Assign tasks to developers (parallel teams for Phase 3, 4, 5 possible)
3. âœ… Start with Phase 1 (setup) - 2-3 hours
4. âœ… Move to Phase 2 (foundational) - 4-6 hours
5. âœ… Implement User Stories 1, 2, 3 in parallel or sequence - 8-12 hours each
6. âœ… Phase 6 polish - 2-3 hours
7. âœ… **Total estimated effort**: 30-40 developer-hours for complete implementation

## Success Criteria per Phase

- **Phase 1** âœ…: All imports work, pytest runs, conftest.py provides fixtures
- **Phase 2** âœ…: All loaders instantiate, models validate, orchestrator logic testable in isolation
- **Phase 3** âœ…: T017-T023 tests pass, endpoint returns correct responses, concurrency works
- **Phase 4** âœ…: T032-T054 tests pass, validation rejects all invalid formats clearly
- **Phase 5** âœ…: T055-T069 tests show <500ms p95, 100+ concurrent handled, caching effective (91 tests passing)
- **Phase 6** âœ…: All 84 tasks complete, code coverage 73%, comprehensive error handling, deployment ready
