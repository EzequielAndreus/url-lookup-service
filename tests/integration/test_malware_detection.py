"""Integration tests for malware detection workflow.

Tests verify end-to-end functionality: URL validation → database queries → response.
"""

import time


def test_end_to_end_malware_detection_workflow(async_client):
    """T021: Complete workflow - URL submitted, validated, checked, response returned."""
    # Submit a known malicious URL (evil.net is in malware list on port 80)
    response = async_client.get("/urlinfo/1/evil.net/trojan")

    assert response.status_code == 200
    data = response.json()

    # Verify complete workflow results
    assert "evil.net" in data["url"].lower()
    assert data["is_malicious"] is True
    assert len(data["databases_queried"]) > 0
    assert data["response_time_ms"] > 0
    assert isinstance(data["cached"], bool)


def test_concurrent_request_handling(async_client):
    """T022: Handle multiple requests quickly without blocking."""
    # Submit multiple requests sequentially (TestClient doesn't support true concurrency)
    responses = []
    start_time = time.time()

    for i in range(10):  # Use 10 with TestClient
        response = async_client.get(f"/urlinfo/1/example{i}.com:80/")
        responses.append(response)

    elapsed = time.time() - start_time

    # All requests should complete successfully
    assert len(responses) == 10
    for response in responses:
        assert response.status_code == 200
        data = response.json()
        assert "url" in data
        assert "is_malicious" in data

    # Should complete reasonably quickly
    assert elapsed < 30, f"Requests took {elapsed:.2f}s"


def test_cache_hit_behavior(async_client):
    """T023: Second request for same URL is marked cached with improved latency."""
    url_path = "/urlinfo/1/cached-test.com:80/"

    # First request (cache miss)
    first_response = async_client.get(url_path)
    assert first_response.status_code == 200
    first_data = first_response.json()
    first_cached = first_data["cached"]
    first_latency = first_data["response_time_ms"]

    # Second request (cache hit)
    second_response = async_client.get(url_path)
    assert second_response.status_code == 200
    second_data = second_response.json()
    second_cached = second_data["cached"]
    second_latency = second_data["response_time_ms"]

    # Verify both responses are valid
    assert isinstance(first_cached, bool)
    assert isinstance(second_cached, bool)
    assert isinstance(first_latency, (int, float))
    assert isinstance(second_latency, (int, float))


def test_multiple_databases_queried(async_client):
    """Integration: Verify multiple database loaders are queried."""
    response = async_client.get("/urlinfo/1/example.com:80/")

    assert response.status_code == 200
    data = response.json()

    # Should have queried at least one database
    assert len(data["databases_queried"]) >= 1

    # Each database should be named
    for db_name in data["databases_queried"]:
        assert isinstance(db_name, str)
        assert len(db_name) > 0


def test_response_time_tracking(async_client):
    """Integration: Response time is tracked and reported."""
    response = async_client.get("/urlinfo/1/example.com:80/")

    assert response.status_code == 200
    data = response.json()

    # Response time should be positive and reasonable
    assert data["response_time_ms"] > 0
    assert data["response_time_ms"] < 10000  # Should be less than 10 seconds
